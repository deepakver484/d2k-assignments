<h1 align="center">Data Engineering Challenge: New York Taxi Data Processing</h1>

## Objective

The objective of this project is to demonstrate proficiency in handling and analyzing large datasets by developing a robust data pipeline using the New York Taxi Trip dataset. 
The project focuses on the following key goals.

<h2 align = "center"> Project Files </h2>


| **File Name**                                                                                                 | **Description**                              |
|---------------------------------------------------------------------------------------------------------------|----------------------------------------------|
| [**analysis.py**](https://github.com/deepakver484/d2k-assignments/blob/deepak/analysis.py)                   | Python script for data analysis.            |
| [**main.py**](https://github.com/deepakver484/d2k-assignments/blob/deepak/main.py)                           | Main pipeline script for executing tasks.   |
| [**app.log**](https://github.com/deepakver484/d2k-assignments/blob/deepak/app.log)                           | Log file capturing application logs.       |
| [**app.py**](https://github.com/deepakver484/d2k-assignments/blob/deepak/app.py)                             | Streamlit application script for UI.        |
| [**Clean_data.py**](https://github.com/deepakver484/d2k-assignments/blob/deepak/Clean_data.py)               | Script for cleaning and preprocessing data. |
| [**Extract_data.py**](https://github.com/deepakver484/d2k-assignments/blob/deepak/Extract_data.py)            | Script for extracting data from sources.    |
| [**requirements.txt**](https://github.com/deepakver484/d2k-assignments/blob/deepak/requirements.txt)        | Lists Python dependencies for the project.  |
| [**Sql_database.py**](https://github.com/deepakver484/d2k-assignments/blob/deepak/Sql_database.py)            | Script for SQL database operations.         |
| [**scraped_data**](https://github.com/deepakver484/d2k-assignments/tree/deepak/scraped_data)                 | Folder containing scraped data files.      |
### How to Use

1. Clone the repository.
2. Install the required packages listed in `requirements.txt` using `pip install -r requirements.txt`.
3. Run `main.py` to start the application.





